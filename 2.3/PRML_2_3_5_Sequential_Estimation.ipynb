{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PRML_2_3_5_Sequential_Estimation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "71OXfM7eMH5i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. 3. 5 순차 추정"
      ]
    },
    {
      "metadata": {
        "id": "jle-zctxMNK5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 순차 추정의 방법\n",
        "* 한 번에 한 샘플을 연산하고 버림\n",
        "* 데이터가 매우 커서 한 번에 계산이 불가능할 때 사용\n",
        "* 식 $(2.121)$에서 $\\mathrm{\\mu}_{ML}$ 을 업데이트 방식으로 바꾸면,\n",
        "\n",
        "$$\n",
        "{\\pmb \\mu}_{ML}^{(N)} = \\frac{1}{N} \\sum_{n=1}^{N}{\\bf x}_n = \\frac{1}{N}{\\bf x}_N + \\frac{1}{N}\\sum_{n=1}^{N-1}{\\bf x}_n\\\\\n",
        "= \\frac{1}{N}{\\bf x}_N + \\frac{N-1}{N}{\\pmb \\mu}_{ML}^{(N-1)}={\\pmb \\mu}_{ML}^{(N-1)}+\\frac{1}{N}({\\bf x}_N-{\\pmb \\mu}_{ML}^{(N-1)}) \\qquad{(2.126)}\n",
        "$$\n",
        "\n",
        "* $N-1$ 개의 데이터로부터 추정된 ${\\pmb \\mu}_{ML}^{(N-1)}$, 그리고 $ N $ 번째 관측된 데이터를 이용하여 $ {\\pmb \\mu}_{ML}^{(N)} $ 을 구함\n",
        "* $N$ 의 값이 증가할수록 새로 관측되는 데이터의 기여도가 점점 작아지게 된다.\n",
        "* 한번에 계산을 처리하는 배치 방식으로부터 식을 유도해 내었기 때문에 실제 결과는 동일하게 된다.\n",
        "* 이런 방식은 매우 유용하지만 배치 방식의 식에서 업데이트 방식의 식을 항상 유도할 수 있는 것은 아니다.\n",
        "* 따라서 좀 더 일반화된 방식의 순차 처리 방식에 대해 알아볼 것이다."
      ]
    },
    {
      "metadata": {
        "id": "_oQa70PeU6kb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Robbins & Monro 알고리즘\n",
        "* 랜덤 변수 $ \\theta $ 와 $ z$\n",
        "* 이 변수들에 대한 결합 분포는 $p(z, \\theta)$\n",
        "* $\\theta$ 가 주어졌을 때 $z$ 에 대한 평균의 함수를 정의\n",
        "\n",
        "$$\n",
        "f(\\theta)\\equiv E[z|\\theta] = \\int zp(z|\\theta)dz \\qquad{(2.127)}\n",
        "$$\n",
        "\n",
        "* 이러한 형태의 함수를 회귀(regression) 함수라고 함\n",
        "* $f(\\theta^{*}) = 0$ 를 만족하는 $\\theta^{*}$ 를 찾는 것이 목표\n",
        "\n",
        "    ![그림 2.10]( https://github.com/norman3/prml/blob/gh-pages/images/Figure2.10.png?raw=true)\n",
        "\n",
        "* 여기서 관찰 데이터는 $z$ (파란색 점)\n",
        "* $z$ 와 $\\theta$ 와 관련된 데이터가 충분히 주어진다면 직접적으로 우리가 원하는 값을 구할 수 있음\n",
        "* 하지만 관찰 데이터가 너무 커서 전체로 주어지지 않고 하나씩 업데이트 된다고 가정\n",
        "    * $z$ 에 대한 조건부 분산(conditional variance)은 유한한 값을 가짐\n",
        "\n",
        "    $$\n",
        "    E[(z-f)^2|\\theta]<\\infty\n",
        "    \\qquad{(2.128)}\n",
        "    $$\n",
        "\n",
        "* 또한,\n",
        "    * 임의의 $\\theta$ 에 대해 $\\theta \\gt \\theta^*$ 이면 $f(\\theta) \\gt 0$\n",
        "    * 임의의 $\\theta$ 에 대해 $\\theta \\lt \\theta^*$ 이면 $f(\\theta) \\lt 0$\n",
        "\n",
        "* 이 상황에서 $\\theta^*$ 를 추정하는 방법\n",
        "\n",
        "$$\n",
        "\\theta^{(N)} = \\theta^{(N-1)} - a_{N-1} z(\\theta^{N-1}) \\qquad{(2.129)}\n",
        "$$\n",
        "\n",
        "* 이 식을 이용하여 순차적으로 들어오는 데이터를 넣어 추정 가능\n",
        "* 여기서 $z(\\theta(N))$ 은 $N$ 번째의 $\\theta$ 값이 들어왔을 때의 출력값\n",
        "* 계수 ${a_N}$ 은 연속적인 양의 실수\n",
        "\n",
        "$$\n",
        "\\lim_{N\\rightarrow\\infty}a_N=0 \\qquad{(2.130)} \\\\\n",
        "\\sum_{N=1}^{\\infty}a_N=\\infty \\qquad{(2.131)} \\\\\n",
        "\\sum_{N-1}^{\\infty}a_N^2<\\infty \\qquad{(2.132)}\n",
        "$$\n",
        "\n",
        "* 위의 세 식은 추정이 반복될수록 (즉, $N$ 이 커질수록):\n",
        "    * $\\lim_{N\\rightarrow\\infty}a_N=0$ : $\\theta$ 가 특정 값에 수렴\n",
        "    * $\\sum_{N=1}^{\\infty}a_N=\\infty$ : root 를 찾기도 전에 임의 값에 수렴하지 않도록\n",
        "    * $\\sum_{N-1}^{\\infty}a_N^2 \\lt\\infty$ : 축적되는 노이즈가 유한하다는 가정에 의해 수렴된 상태를 깨지 않음\n",
        "\n",
        "* 결론\n",
        "    * Robbins & Monro 가 위의 식이 성립한다는 것을 증명\n",
        "    * 위와 같은 식 전개를 가우시안 모델에도 그대로 적용하여,\n",
        "    * 파라미터의 온라인 업데이트가 가능한 모델로 변환할수 있음"
      ]
    },
    {
      "metadata": {
        "id": "4aEfMGb_jDcl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MLE 적용\n",
        "\n",
        "* 가우시안 모델에서 $\\theta_{ML}$ 의 값은 음의 로그 가능도 함수를 한 번 미분하여 얻을 수 있음\n",
        "\n",
        "$$\n",
        "\\frac{\\partial}{\\partial\\theta}\\left.\\left\\{-\\frac{1}{N}\\sum_{n=1}^{N}\\ln p(x_n|\\theta)\\right\\}\\right|_{\\theta_{MLE}}=0 \\qquad{(2.133)}\n",
        "$$\n",
        "\n",
        "* $N\\rightarrow\\infty$ 로 하여 미분 식과 합의 식을 교환한 뒤 일반화\n",
        "\n",
        "$$\n",
        "-\\lim_{n\\rightarrow\\infty}\\frac{1}{N}\\sum_{n=1}^{N}\\frac{\\partial}{\\partial\\theta}\\ln p(x_n|\\theta) = E_x\\left[-\\frac{\\partial}{\\partial\\theta}\\ln p(x|\\theta)\\right] \\qquad{(2.134)}\n",
        "$$\n",
        "\n",
        "* 이제 Robbins & Monro 의 식과 동일\n",
        "    * 가능도 함수의 해를 구하는 것은 회귀 함수의 해를 구하는 문제와 동일\n",
        "    * 이제 Robbins & Monro 식을 적용\n",
        "\n",
        "$$\n",
        "\\theta^{(N)} = \\theta^{(N-1)} - a_{N-1}\\frac{\\partial}{\\partial\\theta^{(N-1)}}\\left[-\\ln p(x_N|\\theta^{(N-1)})\\right] \\qquad{(2.135)}\n",
        "$$\n",
        "\n",
        "* $\\ln p(x_n|\\theta)$ 는 $\\ln p(x_n|\\theta)=\\frac{1}{2\\sigma^2}(x_n-\\theta)^2$\n",
        "* 앞서 구한 식에 대입을 하면,\n",
        "\n",
        "$$\n",
        "z=\\frac{\\partial}{\\partial\\mu_{ML}}[-\\ln p(x|\\mu_{ML}, \\sigma^2)]=-\\frac{1}{\\sigma^2}(x-\\mu_{ML}) \\qquad{(2.136)}\n",
        "$$\n",
        "\n",
        "* 모든 $x$ 에 대해 평균 공식을 대입하면 $-\\frac{1}{\\sigma^2}(\\mu-\\mu_{ML})$,  ($\\frac{1}{N}\\sum x_i=\\mu$)\n",
        "* $E[z|\\theta]$ 는 회귀 식이므로 $z$ 에 대해 정규분포로 표현이 가능\n",
        "* 이 때 이 정규 분포의 평균 값은 실제 회귀 함수가 되며, $-\\frac{1}{\\sigma^2}(\\mu-\\mu_{ML})$\n",
        "* 정규 분포의 평균 값에 대한 연결선은 직선의 함수\\ (붉은색)\n",
        "    ![그림 2.11]( https://github.com/norman3/prml/blob/gh-pages/images/Figure2.11.png?raw=true)\n",
        "\n",
        "* 값이 0 을 만족하는 값이 우리가 찾고자 하는 $\\mu_{ML}$ 의 해\n",
        "* $a_N=\\sigma^2/N$ 으로 놓고 식을 전개하면 배치 방식의 전개와 동일한 식을 얻을 수 있음"
      ]
    }
  ]
}